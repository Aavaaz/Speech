{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1719477887572
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1719477891160
        }
      },
      "outputs": [],
      "source": [
        "# MODEL_CHECKPOINT = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "MODEL_CHECKPOINT = \"google/flan-t5-small\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719477372925
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "text_to_translate = \"Hello, how are you today?\"\n",
        "\n",
        "def translate(text):\n",
        "    input_ids = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"]\n",
        "    output = model.generate(input_ids)\n",
        "    translated_text = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
        "    return translated_text\n",
        "\n",
        "print(translate(text_to_translate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>og_transcription</th>\n",
              "      <th>ms_asr_transcript/ion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4729</td>\n",
              "      <td>4729</td>\n",
              "      <td>4729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>4729</td>\n",
              "      <td>705</td>\n",
              "      <td>2120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>./data/audios/test/1249120_43453425_58166571.wav</td>\n",
              "      <td>When I stand up too quickly I start to feel di...</td>\n",
              "      <td>No speech could be recognized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    file  \\\n",
              "count                                               4729   \n",
              "unique                                              4729   \n",
              "top     ./data/audios/test/1249120_43453425_58166571.wav   \n",
              "freq                                                   1   \n",
              "\n",
              "                                         og_transcription  \\\n",
              "count                                                4729   \n",
              "unique                                                705   \n",
              "top     When I stand up too quickly I start to feel di...   \n",
              "freq                                                   26   \n",
              "\n",
              "                ms_asr_transcript/ion  \n",
              "count                            4729  \n",
              "unique                           2120  \n",
              "top     No speech could be recognized  \n",
              "freq                               29  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/audios/train.csv')\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>og_transcription</th>\n",
              "      <th>ms_asr_transcript/ion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./data/audios/test/1249120_43453425_58166571.wav</td>\n",
              "      <td>When I remember her I feel down</td>\n",
              "      <td>When I remember her, I feel.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./data/audios/test/1249120_43719934_43347848.wav</td>\n",
              "      <td>When I carry heavy things I feel like breaking...</td>\n",
              "      <td>When I carry heavy things I feel like breaking...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./data/audios/test/1249120_43719934_53187202.wav</td>\n",
              "      <td>there is too much pain when i move my arm</td>\n",
              "      <td>There is so much pain when I move my arm.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./data/audios/test/1249120_31349958_55816195.wav</td>\n",
              "      <td>My son had his lip pierced and it is swollen a...</td>\n",
              "      <td>My flip Pierce into this one is inside on his ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./data/audios/test/1249120_43719934_82524191.wav</td>\n",
              "      <td>My muscles in my lower back are aching</td>\n",
              "      <td>My muscles in my lower back are aching.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               file  \\\n",
              "0  ./data/audios/test/1249120_43453425_58166571.wav   \n",
              "1  ./data/audios/test/1249120_43719934_43347848.wav   \n",
              "2  ./data/audios/test/1249120_43719934_53187202.wav   \n",
              "3  ./data/audios/test/1249120_31349958_55816195.wav   \n",
              "4  ./data/audios/test/1249120_43719934_82524191.wav   \n",
              "\n",
              "                                    og_transcription  \\\n",
              "0                    When I remember her I feel down   \n",
              "1  When I carry heavy things I feel like breaking...   \n",
              "2          there is too much pain when i move my arm   \n",
              "3  My son had his lip pierced and it is swollen a...   \n",
              "4             My muscles in my lower back are aching   \n",
              "\n",
              "                               ms_asr_transcript/ion  \n",
              "0                       When I remember her, I feel.  \n",
              "1  When I carry heavy things I feel like breaking...  \n",
              "2          There is so much pain when I move my arm.  \n",
              "3  My flip Pierce into this one is inside on his ...  \n",
              "4            My muscles in my lower back are aching.  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dropna(inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "SOURCE = 'ms_asr_transcription'\n",
        "\n",
        "TARGET = 'og_transcription'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1719477376001
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df[SOURCE], df[TARGET], test_size=0.10,\n",
        "                                                    shuffle=True,\n",
        "                                                    random_state=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1719477377905
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def prep_data_for_model_fine_tuning(source_lang: list, target_lang: list) -> list:\n",
        "\n",
        "    data_dict = dict()\n",
        "    data_dict['data'] = []\n",
        "\n",
        "    for sr_text, tr_text in zip(source_lang, target_lang):\n",
        "        temp_dict = dict()\n",
        "        temp_dict[SOURCE] = sr_text\n",
        "        temp_dict[TARGET] = tr_text\n",
        "\n",
        "        data_dict['data'].append(temp_dict)\n",
        "\n",
        "    return data_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1719477447676
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "training_data = prep_data_for_model_fine_tuning(x_train.values, y_train.values)\n",
        "testing_data = prep_data_for_model_fine_tuning(x_test.values, y_test.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'ms_asr_transcript/ion': 'I feel like the around.',\n",
              "  'og_transcription': 'I feel like the world goes round and round'},\n",
              " {'ms_asr_transcript/ion': \"Fell's skull is cracked like nuts.\",\n",
              "  'og_transcription': 'fell skull is cracked like nuts'},\n",
              " {'ms_asr_transcript/ion': 'Severe pain in the upper left side of chest and may have pain to back.',\n",
              "  'og_transcription': 'severe pain in the upper left side of chest and may have pain to back'},\n",
              " {'ms_asr_transcript/ion': 'When I get up I see my skin vague.',\n",
              "  'og_transcription': 'When i get up i see my skin vague'},\n",
              " {'ms_asr_transcript/ion': 'When I eat I feel my stomach hurts.',\n",
              "  'og_transcription': 'When i eat i feel my stomach hurts'}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data['data'][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1719477675472
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "MAX_INPUT_LENGTH = 128\n",
        "\n",
        "def generate_model_ready_dataset(dataset: list, source: str, target: str,\n",
        "                                 model_checkpoint: str,\n",
        "                                 tokenizer: AutoTokenizer):\n",
        "\n",
        "    preped_data = []\n",
        "\n",
        "    for row in dataset:\n",
        "        inputs = row[source]\n",
        "        targets = row[target]\n",
        "\n",
        "        model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH,\n",
        "                                 truncation=True, padding=True)\n",
        "\n",
        "        model_inputs['data'] = row\n",
        "\n",
        "        # setup the tokenizer for targets\n",
        "        with tokenizer.as_target_tokenizer():\n",
        "            labels = tokenizer(targets, max_length=MAX_INPUT_LENGTH,\n",
        "                                 truncation=True, padding=True)\n",
        "            model_inputs['labels'] = labels['input_ids']\n",
        "\n",
        "        preped_data.append(model_inputs)\n",
        "\n",
        "    return preped_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719477677780
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_data = generate_model_ready_dataset(dataset=training_data['data'],\n",
        "                                        tokenizer=tokenizer,\n",
        "                                        source=SOURCE,\n",
        "                                        target=TARGET,\n",
        "                                        model_checkpoint=MODEL_CHECKPOINT)\n",
        "\n",
        "test_data = generate_model_ready_dataset(dataset=testing_data['data'],\n",
        "                                        tokenizer=tokenizer,\n",
        "                                        source=SOURCE,\n",
        "                                        target=TARGET,\n",
        "                                        model_checkpoint=MODEL_CHECKPOINT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1719477690654
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# train_data\n",
        "# test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719477720255
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame.from_records(train_data)\n",
        "train_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1719477728972
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "test_df = pd.DataFrame.from_records(test_data)\n",
        "test_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1719477791094
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['attention_mask', 'data', 'input_ids', 'labels'],\n",
              "    num_rows: 4256\n",
              "})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "MODEL_INTENT = 'asr_correction'\n",
        "\n",
        "trained_model_name = f'{MODEL_CHECKPOINT.split('/')[-1]}-finetuned-{MODEL_INTENT}'\n",
        "model_args = Seq2SeqTrainingArguments(\n",
        "    trained_model_name,\n",
        "    # evaluation_strategy='epoch',\n",
        "    learning_rate=2e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.02,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=10,\n",
        "    predict_with_generate=True\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model.to(device),\n",
        "    model_args,\n",
        "    train_dataset=train_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.save_model(f\"{MODEL_CHECKPOINT}-finetuned-{MODEL_INTENT}\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
