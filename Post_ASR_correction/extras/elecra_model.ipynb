{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1719477887572
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer, ElectraModel\n",
        "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1719477891160
        }
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"monsoon-nlp/hindi-bert\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = ElectraModel.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ElectraForCausalLM were not initialized from the model checkpoint at monsoon-nlp/hindi-bert and are newly initialized: ['generator_lm_head.bias', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.dense.bias', 'generator_predictions.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# from transformers import AutoTokenizer, ElectraForCausalLM, ElectraConfig\n",
        "# import torch\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "# config = ElectraConfig.from_pretrained(model_checkpoint)\n",
        "# config.is_decoder = True\n",
        "# model = ElectraForCausalLM.from_pretrained(model_checkpoint, config=config)\n",
        "\n",
        "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
        "# outputs = model(**inputs)\n",
        "\n",
        "# prediction_logits = outputs.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1719477372925
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[ 3.1968, -0.2916, -1.3961,  ...,  0.6601,  0.0767, -1.0141],\n",
            "         [-0.2994,  1.0305,  0.7881,  ...,  0.0060,  0.3606,  0.3605],\n",
            "         [ 0.1282,  0.8684,  0.5141,  ..., -0.3899,  0.9929,  0.0631],\n",
            "         ...,\n",
            "         [-0.9911,  0.8092, -0.8361,  ..., -1.5284,  1.9849, -0.4128],\n",
            "         [-0.0386,  1.3650,  0.6784,  ..., -0.1884,  0.1843,  0.2917],\n",
            "         [ 2.1853,  1.2530, -1.7943,  ..., -0.3426, -1.8372, -1.2427]]],\n",
            "       grad_fn=<ViewBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "text_to_translate = \"आज आप कैसे हैं?\"\n",
        "\n",
        "def translate(text):\n",
        "    input_ids = tokenizer(text, return_tensors=\"pt\")\n",
        "    output = model(**input_ids)\n",
        "    translated_text = (output)\n",
        "    return translated_text\n",
        "\n",
        "print(translate(text_to_translate))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 6.4474e-04, -2.5465e-01, -3.0314e+00,  ...,  3.9161e-03,\n",
              "           5.9308e-02, -4.0211e+00],\n",
              "         [ 9.1006e-04,  1.4979e-03,  1.4981e-01,  ...,  3.7161e-03,\n",
              "           3.2461e-02,  9.8596e-01],\n",
              "         [ 9.0351e-04,  2.3459e-02,  5.0762e-01,  ...,  3.6704e-03,\n",
              "           3.5678e-02,  8.1919e-01],\n",
              "         ...,\n",
              "         [ 6.2031e-04,  6.2428e-02, -3.2081e+00,  ...,  3.5274e-03,\n",
              "           4.6542e-02, -1.5137e+00],\n",
              "         [ 9.7176e-04,  7.3584e-03, -4.9148e-01,  ...,  3.6916e-03,\n",
              "           4.5545e-02,  8.9428e-01],\n",
              "         [ 6.4474e-04, -2.5465e-01, -3.0314e+00,  ...,  3.9161e-03,\n",
              "           5.9307e-02, -4.0211e+00]]], grad_fn=<NativeLayerNormBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_to_translate = \"आज आप कैसे हैं?\"\n",
        "\n",
        "input_ids = tokenizer(text_to_translate, return_tensors=\"pt\")\n",
        "output = model(**input_ids)\n",
        "output"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
