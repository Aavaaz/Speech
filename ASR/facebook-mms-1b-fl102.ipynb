{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, AutoProcessor\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "waveform, sample_rate = torchaudio.load(\"audios/male.wav\", format=\"wav\")\n",
    "print(sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/mms-1b-fl102 were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/mms-1b-fl102 and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"facebook/mms-1b-fl102\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(waveform[0], sampling_rate=16000, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "\n",
    "ids = torch.argmax(outputs, dim=-1)[0]\n",
    "transcription = processor.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tht red fandedy th fonds te red at o heffr tht ou keep adcrat caverage bat refor prices to sayd manledy is takeng rounday to get en strat arway than the bankers expected gorteringthe ride for rens compani ono rin her hap forter retarment an cont  gast is herfer that an adrat nows arfthr faving rounds ar hers way tasstd on a 2wnaut of barn f ree th fles in clad on faire wen a tider ar gif hopin ferm is incresting es e don or ratsing or gasing ned a bider regt not b pessionos on bout wor a proters ra te wareing proce red on a frent surface on snowt har tha siparat cay thir separat system neused a finger 1septeeth munite fr old sharp atage their hofs a dn con is usualy abaut barn for fialders ridder har andenother year sem wat beutifl chairs omats chaffs barehouses etc.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(processor= processor, model=model):\n",
    "    inputs = processor(waveform[0], sampling_rate=16000, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "\n",
    "    ids = torch.argmax(outputs, dim=-1)[0]\n",
    "    transcription = processor.decode(ids)\n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.set_target_lang(language)\n",
    "model.load_adapter(language)\n",
    "\n",
    "inputs = processor(waveform[0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "\n",
    "ids = torch.argmax(outputs, dim=-1)[0]\n",
    "transcription = processor.decode(ids)\n",
    "transcription"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
