{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC, AutoProcessor\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "waveform, sample_rate = torchaudio.load(\"audios/male.wav\", format=\"wav\")\n",
    "print(sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"facebook/mms-1b-fl102\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(waveform[0], sampling_rate=16000, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "\n",
    "ids = torch.argmax(outputs, dim=-1)[0]\n",
    "transcription = processor.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tht red fandedy th fonds te red at o heffr tht ou keep adcrat caverage bat refor prices to sayd manledy is takeng rounday to get en strat arway than the bankers expected gorteringthe ride for rens compani ono rin her hap forter retarment an cont  gast is herfer that an adrat nows arfthr faving rounds ar hers way tasstd on a 2wnaut of barn f ree th fles in clad on faire wen a tider ar gif hopin ferm is incresting es e don or ratsing or gasing ned a bider regt not b pessionos on bout wor a proters ra te wareing proce red on a frent surface on snowt har tha siparat cay thir separat system neused a finger 1septeeth munite fr old sharp atage their hofs a dn con is usualy abaut barn for fialders ridder har andenother year sem wat beutifl chairs omats chaffs barehouses etc.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(processor= processor, model=model):\n",
    "    inputs = processor(waveform[0], sampling_rate=16000, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs).logits\n",
    "\n",
    "    ids = torch.argmax(outputs, dim=-1)[0]\n",
    "    transcription = processor.decode(ids)\n",
    "    return transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'eng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.tokenizer.set_target_lang(language)\n",
    "model.load_adapter(language)\n",
    "\n",
    "inputs = processor(waveform[0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs).logits\n",
    "\n",
    "ids = torch.argmax(outputs, dim=-1)[0]\n",
    "transcription = processor.decode(ids)\n",
    "transcription"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
